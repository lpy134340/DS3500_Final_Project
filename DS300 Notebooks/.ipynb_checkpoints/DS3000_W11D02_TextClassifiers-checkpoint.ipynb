{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"https://yildirimcaglar.github.io/ds3000/ds3000.png\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> Text Classifiers</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Outline\n",
    "1. <a href='#1'>Logistic Regression</a>\n",
    "2. <a href='#2'>Multilayer Perceptron Classifier</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Logistic Regression\n",
    "* Despite its name, a classification algorithm\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"res/game_reviews.csv\")\n",
    "features = data[\"comment\"]\n",
    "target = data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on training set:  0.9012009495880463\n",
      "Classification accuracy on testing set:  0.8217801047120419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "\n",
    "#create the vocabulary based on the training data\n",
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "#encode the words in X_train and X_test based on the vocabulary\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "#train the classifier\n",
    "model = LogisticRegression().fit(X=X_train_vectorized, y=y_train)\n",
    "\n",
    "\n",
    "print(\"Classification accuracy on training set: \", model.score(X_train_vectorized, y_train))\n",
    "print(\"Classification accuracy on testing set: \", model.score(X_test_vectorized, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Probability Estimates\n",
    "* possible to get probability estimates for predictions\n",
    "* use model.predict_proba()\n",
    "    * Returned estimates for all classes are ordered by the label of classes.\n",
    "\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74943183, 0.25056817],\n",
       "       [0.07551562, 0.92448438],\n",
       "       [0.27700778, 0.72299222],\n",
       "       ...,\n",
       "       [0.49807486, 0.50192514],\n",
       "       [0.58939542, 0.41060458],\n",
       "       [0.65454571, 0.34545429]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = pd.DataFrame(model.predict_proba(X_test_vectorized), columns = [\"Not recommended\", \"Recommended\"])\n",
    "proba[\"prediction\"] = model.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not recommended</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.749432</td>\n",
       "      <td>0.250568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075516</td>\n",
       "      <td>0.924484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.277008</td>\n",
       "      <td>0.722992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.590125</td>\n",
       "      <td>0.409875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111302</td>\n",
       "      <td>0.888698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>0.633448</td>\n",
       "      <td>0.366552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>0.498075</td>\n",
       "      <td>0.501925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>0.589395</td>\n",
       "      <td>0.410605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>0.654546</td>\n",
       "      <td>0.345454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4775 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Not recommended  Recommended  prediction\n",
       "0            0.749432     0.250568           0\n",
       "1            0.075516     0.924484           1\n",
       "2            0.277008     0.722992           1\n",
       "3            0.590125     0.409875           0\n",
       "4            0.111302     0.888698           1\n",
       "...               ...          ...         ...\n",
       "4770         0.271429     0.728571           1\n",
       "4771         0.633448     0.366552           0\n",
       "4772         0.498075     0.501925           1\n",
       "4773         0.589395     0.410605           0\n",
       "4774         0.654546     0.345454           0\n",
       "\n",
       "[4775 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multilayer Perceptron Classifier\n",
    "* Simple, feed-forward neural network\n",
    "* hidden_layer_sizes = (10) adds a single hidden layer with 10 hidden units\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on training set:  0.9969278033794163\n",
      "Classification accuracy on testing set:  0.7951832460732984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "\n",
    "#create the vocabulary based on the training data\n",
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "#encode the words in X_train and X_test based on the vocabulary\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "#train the classifier\n",
    "model = MLPClassifier(solver = \"adam\", hidden_layer_sizes = (10), activation =\"relu\", \n",
    "                      random_state = 3000).fit(X=X_train_vectorized, y=y_train)\n",
    "\n",
    "\n",
    "print(\"Classification accuracy on training set: \", model.score(X_train_vectorized, y_train))\n",
    "print(\"Classification accuracy on testing set: \", model.score(X_test_vectorized, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.28296065, -0.22105024, -0.2174355 , ..., -0.23400576,\n",
       "          0.29859513,  0.31121737],\n",
       "        [ 0.13273665, -0.09415211, -0.10321598, ..., -0.08206359,\n",
       "          0.12935822,  0.13261685],\n",
       "        [ 0.00774221,  0.03681403,  0.02944204, ...,  0.02962293,\n",
       "          0.00253839,  0.00299492],\n",
       "        ...,\n",
       "        [-0.01895684,  0.05293769,  0.0586672 , ...,  0.057522  ,\n",
       "         -0.02275426, -0.03385177],\n",
       "        [-0.27278427,  0.2912648 ,  0.27547451, ...,  0.27952719,\n",
       "         -0.2690866 , -0.28629307],\n",
       "        [ 0.10712993, -0.11743189, -0.13380156, ..., -0.12133759,\n",
       "          0.1017334 ,  0.10750843]]),\n",
       " array([[-2.90132981],\n",
       "        [ 3.06195661],\n",
       "        [ 3.19361664],\n",
       "        [ 3.16842952],\n",
       "        [-2.74120839],\n",
       "        [ 3.19857573],\n",
       "        [-2.58825901],\n",
       "        [ 3.12090005],\n",
       "        [-2.74447616],\n",
       "        [-2.64547645]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
